# NICE EEG Preprocessing Pipeline

A modular, configuration-driven EEG preprocessing pipeline using MNE-BIDS. The pipeline uses auxiliary functions for each preprocessing step, allowing you to choose which steps to run, their order, and their parameters through a simple YAML configuration.

## Features

- **MNE-BIDS Integration**: Seamlessly reads EEG data in BIDS format
- **Modular Design**: Each preprocessing step is a separate function
- **Configuration-Driven**: Choose steps, their order, and parameters via YAML
- **Multiple Output Formats**:
  - Clean preprocessed epochs in `.fif` format
  - Clean preprocessed raw data in `.fif` format
  - Interactive HTML reports using MNE Report
  - JSON reports for easy downstream processing
- **Batch Processing**: Process multiple subjects sequentially
- **Command-line Interface**: Easy to use from the terminal

## Installation

1. Clone this repository:
```bash
git clone https://github.com/Laouen/nice-preprocessing.git
cd nice-preprocessing
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

### Process Multiple Subjects

Run the preprocessing pipeline on multiple subjects:

```bash
python -m cli \
    --bids-root /path/to/bids/dataset \
    --subjects 01 02 03 \
    --task rest \
    --config configs/config_example.yaml
```

Or after installing the package:

```bash
eeg-preprocess \
    --bids-root /path/to/bids/dataset \
    --subjects 01 02 03 \
    --task rest \
    --config configs/config_example.yaml
```

### Python API Usage

You can also use the pipeline directly in Python:

```python
import sys
sys.path.insert(0, 'src')
from eeg_preprocessing_pipeline import EEGPreprocessingPipeline

# Load configuration
import yaml
with open('configs/config_example.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Initialize pipeline
pipeline = EEGPreprocessingPipeline(
    bids_root='/path/to/bids/dataset',
    output_root='/path/to/derivatives',
    config=config
)

# Run preprocessing on multiple subjects
results = pipeline.run_pipeline(
    subjects=['01', '02', '03'],
    task='rest'
)

# Access results for each subject
for subject, result in results.items():
    print(f"Subject {subject}: {result}")
```

## Output Structure

The pipeline creates outputs in a BIDS-derivatives structure:

```
derivatives/nice_preprocessing/
├── epochs/
│   └── sub-01/
│       └── eeg/
│           └── sub-01_task-rest_proc-clean_desc-cleaned_epo.fif
└── reports/
    └── sub-01/
        └── eeg/
            ├── sub-01_task-rest_proc-clean_desc-cleaned_report.json
            └── sub-01_task-rest_proc-clean_desc-cleaned_report.html
```

### Output Details

1. **epochs/**: Contains MNE epochs objects saved in `.fif` format (if `save_clean_epochs` step is included)
   - Can be loaded with `mne.read_epochs()`
   - Includes all preprocessing (filtering, artifact removal, baseline correction)

2. **reports/**: Contains preprocessing reports
   - **JSON report**: Preprocessing parameters, quality metrics, steps performed (generated by `generate_json_report` step)
   - **HTML report**: Interactive visualization (generated by `generate_html_report` step)

## Configuration

The pipeline is configuration-driven. You define a list of preprocessing steps, their order, and parameters in a YAML file.

### Available Steps

- **load_data**: Load raw data into memory
- **bandpass_filter**: Apply bandpass filtering
- **notch_filter**: Apply notch filtering
- **reference**: Apply re-referencing
- **ica**: ICA-based artifact removal
- **find_events**: Find events in the data
- **epoch**: Create epochs around events
- **find_bads_channels_threshold**: Find bad channels using threshold-based rejection
- **find_bads_channels_variance**: Find bad channels using variance-based detection
- **find_bads_channels_high_frequency**: Find bad channels using high-frequency variance
- **find_bads_epochs_threshold**: Find and remove bad epochs using threshold-based rejection
- **save_clean_epochs**: Save epochs to .fif file
- **generate_json_report**: Generate JSON report
- **generate_html_report**: Generate HTML report

### Example Configuration

See `configs/config_example.yaml` for a full pipeline with epochs:

```yaml
pipeline:
  - name: load_data
  - name: bandpass_filter
    l_freq: 0.5
    h_freq: 40.0
  - name: reference
    ref_channels: average
    projection: false
  - name: ica
    n_components: 20
    method: fastica
    find_eog: true
    find_ecg: false
    apply: true
  - name: find_events
    shortest_event: 1
  - name: epoch
    tmin: -0.2
    tmax: 0.8
    baseline: [null, 0]
    event_id: null
    reject:
      eeg: 1.5e-04
  - name: save_clean_epochs
  - name: generate_json_report
  - name: generate_html_report
```

See `configs/config_raw_only.yaml` for a simpler pipeline without epoching:

```yaml
pipeline:
  - name: load_data
  - name: bandpass_filter
    l_freq: 1.0
    h_freq: 30.0
  - name: reference
    ref_channels: average
  - name: ica
    n_components: 15
    method: fastica
    find_eog: true
    apply: true
  - name: generate_json_report
```

See `configs/config_with_adaptive_reject.yaml` for a pipeline with adaptive autoreject steps:

```yaml
pipeline:
  - name: load_data
  - name: bandpass_filter
    l_freq: 0.5
    h_freq: 40.0
  - name: reference
    ref_channels: average
    projection: false
  - name: ica
    n_components: 20
    method: fastica
    find_eog: true
    find_ecg: false
    apply: true
  - name: find_events
    shortest_event: 1
  - name: epoch
    tmin: -0.2
    tmax: 0.8
    baseline: [null, 0]
    event_id: null
    reject: null
  - name: find_bads_channels_threshold
    reject:
      eeg: 1.5e-04
    n_epochs_bad_ch: 0.5
  - name: find_bads_channels_variance
    instance: epochs
    zscore_thresh: 4
    max_iter: 2
  - name: find_bads_channels_high_frequency
    instance: epochs
    zscore_thresh: 4
    max_iter: 2
  - name: find_bads_epochs_threshold
    reject:
      eeg: 1.5e-04
    n_channels_bad_epoch: 0.1
  - name: save_clean_epochs
  - name: generate_json_report
  - name: generate_html_report
```

## Command-Line Arguments

- `--bids-root`: Path to BIDS root directory (required)
- `--subjects`: Subject ID(s) to process, space or comma-separated (required)
- `--task`: Task name (optional)
- `--output-root`: Custom output path (optional, defaults to `bids-root/derivatives/nice-preprocessing`)
- `--config`: Path to YAML configuration file (optional)

## Preprocessing Steps Details

Each step can be customized through the configuration:

### 1. load_data
Loads raw data into memory. No parameters needed.

### 2. bandpass_filter
Apply bandpass filtering.
- `l_freq`: High-pass filter frequency (Hz)
- `h_freq`: Low-pass filter frequency (Hz)
- `l_freq_order`: Filter order for high-pass (default: 6)
- `h_freq_order`: Filter order for low-pass (default: 8)
- `picks`: Optional channel indices to filter
- `n_jobs`: Number of parallel jobs (default: 1)

### 3. notch_filter
Apply notch filtering to remove line noise.
- `freqs`: Frequencies to notch filter (e.g., [50.0, 100.0])
- `notch_widths`: Width of notch filters (optional)
- `method`: Filtering method (default: 'fft')
- `picks`: Optional channel indices to filter
- `n_jobs`: Number of parallel jobs (default: 1)

### 4. reference
Apply re-referencing.
- `ref_channels`: Reference channels ('average' or channel names)
- `instance`: Which data instance to reference - 'raw' or 'epochs' (default: 'epochs')
- `projection`: Whether to use projection (true/false, default: true)
- `apply`: Whether to apply the reference immediately (true/false, default: true)

### 5. ica
ICA-based artifact removal.
- `n_components`: Number of ICA components (default: 20)
- `method`: ICA method ('fastica', 'infomax', 'picard', default: 'fastica')
- `random_state`: Random state for reproducibility (default: 97)
- `find_eog`: Automatically find EOG artifacts (true/false, default: true)
- `find_ecg`: Automatically find ECG artifacts (true/false, default: false)
- `apply`: Apply ICA to remove artifacts (true/false, default: true)

### 6. find_events
Find events in the data.
- `shortest_event`: Minimum event duration in samples (default: 1)

### 7. epoch
Create epochs around events.
- `tmin`: Start time before event (seconds, default: -0.2)
- `tmax`: End time after event (seconds, default: 0.5)
- `baseline`: Baseline correction window (tuple or null, default: (null, 0.0))
- `event_id`: Event IDs to include (dict or null for all)
- `reject`: Rejection criteria (dict with channel type keys, optional)

### 8. find_bads_channels_threshold
Find bad channels using threshold-based rejection. Marks channels as bad if they exceed rejection thresholds in too many epochs.
- `picks`: Channel indices to check (optional, default: EEG channels)
- `reject`: Rejection thresholds by channel type (e.g., `{"eeg": 150e-6}`)
- `n_epochs_bad_ch`: Fraction or number of epochs a channel must be bad in to be marked as bad (default: 0.5)
- `apply_on`: List of instances to mark bad channels on (default: ['epochs'])

### 9. find_bads_channels_variance
Find bad channels using variance-based detection. Identifies channels with abnormally high or low variance.
- `instance`: Which data instance to use - 'raw' or 'epochs' (default: 'epochs')
- `picks`: Channel indices to check (optional, default: EEG channels)
- `zscore_thresh`: Z-score threshold for outlier detection (default: 4)
- `max_iter`: Maximum iterations for iterative outlier removal (default: 2)
- `apply_on`: List of instances to mark bad channels on (default: [instance])

### 10. find_bads_channels_high_frequency
Find bad channels using high-frequency variance. Detects channels with excessive high-frequency noise.
- `instance`: Which data instance to use - 'raw' or 'epochs' (default: 'epochs')
- `picks`: Channel indices to check (optional, default: EEG channels)
- `zscore_thresh`: Z-score threshold for outlier detection (default: 4)
- `max_iter`: Maximum iterations for iterative outlier removal (default: 2)
- `apply_on`: List of instances to mark bad channels on (default: [instance])

### 11. find_bads_epochs_threshold
Find and remove bad epochs using threshold-based rejection. Drops epochs that have too many bad channels.
- `picks`: Channel indices to check (optional, default: EEG channels)
- `reject`: Rejection thresholds by channel type (e.g., `{"eeg": 150e-6}`)
- `n_channels_bad_epoch`: Fraction or number of channels that must be bad for an epoch to be rejected (default: 0.1)

### 12. save_clean_epochs
Save epochs to .fif file in BIDS-derivatives format.
- `overwrite`: Whether to overwrite existing files (default: true)

### 13. generate_json_report
Generate JSON report with preprocessing information. No parameters needed.

### 14. generate_html_report
Generate HTML report with interactive visualizations. No parameters needed.

## Batch Processing

The pipeline processes multiple subjects sequentially. Simply pass multiple subject IDs:

```bash
# Process multiple subjects at once
python -m cli \
    --bids-root /path/to/bids/dataset \
    --subjects 01 02 03 04 05 \
    --task rest \
    --config configs/config_example.yaml
```

For HPC/cluster environments, you can create your own SLURM or other batch submission scripts that call the pipeline with subject lists.

## Requirements

- Python >= 3.8
- mne >= 1.5.0
- mne-bids >= 0.14
- numpy >= 1.24.0
- scipy >= 1.11.0
- matplotlib >= 3.7.0 (recommended)
- pandas >= 2.0.0 (recommended)

## License

This project is ready to use for several projects and includes scripts for SLURM execution.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Support

For issues or questions, please open an issue on the GitHub repository. 
